# E2E Object Detection Pipeline with Integrated Compression

## ğŸ¯ Overview

A complete **End-to-End Object Detection Pipeline** that processes multiple video streams in parallel with integrated compression and real-time YOLOv11 inference. This single-file solution provides enterprise-grade video processing with perfect frame preservation and comprehensive performance tracking.

## âœ¨ Key Features

### ğŸš€ **Core Capabilities**
- **Parallel Video Processing**: Process up to 5 video streams simultaneously and independently
- **Integrated Compression**: Frame-level JPEG compression with 100% frame preservation
- **Real-time Object Detection**: YOLOv11 small model with bounding box visualization
- **Perfect Frame Preservation**: Maintains exact input video properties (frames, FPS, duration)
- **Single File Solution**: Complete pipeline in `main.py` - no external dependencies

### ğŸ”§ **Advanced Features**
- **MLflow Integration**: Comprehensive experiment tracking and performance metrics
- **Detailed Performance Analytics**: Per-frame inference timing and processing statistics
- **Configurable Processing**: YAML-based configuration for all pipeline parameters
- **Multi-device Support**: CPU and CUDA GPU processing modes
- **Robust Error Handling**: Graceful error recovery and detailed logging

### ğŸ“Š **Output Generation**
- **Compressed Videos**: High-quality compressed versions of input videos
- **Detection Videos**: Videos with bounding boxes and object labels
- **Performance Reports**: Detailed timing and efficiency metrics
- **Sample Frames**: Extracted frames for quality verification

## ğŸ—ï¸ Architecture

### Pipeline Flow
```
Input Videos (5 streams) â†’ Parallel Processing â†’ Dual Output Generation

For each video stream:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Read Frame  â”‚ â†’ â”‚ Compress     â”‚ â†’ â”‚ Object         â”‚ â†’ â”‚ Write Dual   â”‚
â”‚             â”‚    â”‚ Frame        â”‚    â”‚ Detection      â”‚    â”‚ Outputs      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                      â†“
                                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                              â”‚ Compressed + â”‚
                                                              â”‚ Detection    â”‚
                                                              â”‚ Videos       â”‚
                                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Processing Model
- **Frame-by-Frame Processing**: Each frame goes through compression â†’ detection â†’ output
- **Independent Streams**: Each video processes completely independently
- **No Synchronization**: Videos don't wait for each other
- **100% Preservation**: Every input frame is processed and saved

## ğŸš€ Quick Start

### 1. Installation
```bash
# Clone repository
git clone <repository-url>
cd Theft_Detection_Bacancy

# Install dependencies using uv
uv sync

# Note: uv automatically manages the virtual environment
```

#### Package Management with UV

Managing dependencies is simple with uv:

```bash
# Add a new package (uv manages version automatically)
uv add package-name

# Add a package with specific version
uv add package-name==1.2.3

# Remove a package
uv remove package-name

# Update all packages
uv sync --upgrade
```

**Benefits:**
- ğŸ¯ UV automatically resolves compatible versions
- ğŸ“¦ Updates `pyproject.toml` and `uv.lock` automatically
- ğŸ”„ No need to manually edit dependency files
- âš¡ Fast dependency resolution and installation

### 2. Configuration
```bash
# Edit config.yaml to set your video paths
nano config.yaml
```

### 3. Run Pipeline
```bash
# Validate configuration
uv run main.py --validate

# Run with parallel processing (recommended)
uv run main.py --parallel-mode threading --gpu cpu

# Run with GPU (if available)
uv run main.py --parallel-mode threading --gpu cuda
```

## ğŸ“ Project Structure

```
Theft_Detection_Bacancy/
â”œâ”€â”€ ğŸ“„ main.py                 # Complete E2E pipeline (single file)
â”œâ”€â”€ âš™ï¸  config.yaml            # Configuration file
â”œâ”€â”€ ğŸ“¦ pyproject.toml         # Project dependencies and metadata
â”œâ”€â”€ ğŸ”’ uv.lock                # Dependency lock file
â”œâ”€â”€ ğŸ“‹ requirements.txt        # Legacy pip dependencies (for reference)
â”œâ”€â”€ ğŸ“– README.md              # This file
â”œâ”€â”€ ğŸ› ï¸  INSTALLATION.md        # Detailed installation guide
â”œâ”€â”€ ğŸ“ videos/                # Input videos directory
â”‚   â”œâ”€â”€ sample_video_1.mp4
â”‚   â”œâ”€â”€ sample_video_2.mp4
â”‚   â”œâ”€â”€ sample_video_3.mp4
â”‚   â”œâ”€â”€ sample_video_4.mp4
â”‚   â””â”€â”€ sample_video_5.mp4
â”œâ”€â”€ ğŸ“ output/                # Generated outputs
â”‚   â”œâ”€â”€ compressed/           # Compressed videos (100% frame preservation)
â”‚   â”œâ”€â”€ detections/          # Detection videos with bounding boxes
â”‚   â””â”€â”€ frames/              # Sample extracted frames
â”œâ”€â”€ ğŸ“ logs/                  # Pipeline execution logs
â””â”€â”€ ğŸ“ mlruns/               # MLflow experiment tracking data
```

## âš™ï¸ Configuration

### Basic Configuration (config.yaml)
```yaml
# Input Videos (up to 5 streams)
input_videos:
- path: videos/sample_video_1.mp4
  stream_id: sample_stream_1
- path: videos/sample_video_2.mp4
  stream_id: sample_stream_2

# Model Configuration
model:
  directory: model               # Folder containing your YOLO checkpoint
  # name: custom_model.pt        # Optional explicit override (if needed)
  device: cpu                    # or 'cuda' for GPU
  confidence_threshold: 0.5
  iou_threshold: 0.45

# Compression Settings
compression:
  enabled: true
  quality: 85                   # JPEG quality (1-100)

# Output Configuration
output:
  save_detection_videos: true
  save_compressed_videos: true
  detection_videos_path: output/detections
  compressed_videos_path: output/compressed

# Performance Settings
performance:
  max_workers: 5               # Parallel video processing
  frame_buffer_size: 200       # Memory buffer size
```

## ğŸ® Usage Examples

### Basic Usage
```bash
# Process videos with default settings
uv run main.py

# Use specific configuration file
uv run main.py --config custom_config.yaml

# Run without MLflow tracking
uv run main.py --no-mlflow
```

### Advanced Usage
```bash
# Sequential processing (for debugging)
uv run main.py --parallel-mode sequential

# GPU processing with custom config
uv run main.py --gpu cuda --config gpu_config.yaml

# Validation only (no processing)
uv run main.py --validate
```

### Command Line Options
```bash
uv run main.py [OPTIONS]

Options:
  --config PATH              Configuration file path (default: config.yaml)
  --validate                 Validate configuration only
  --gpu {auto,cuda,cpu}     GPU device selection (default: auto)
  --no-mlflow               Disable MLflow tracking
  --parallel-mode {threading,sequential}  Processing mode (default: threading)
  --log-level {DEBUG,INFO,WARNING,ERROR}  Logging level (default: INFO)
  --version                 Show version information
  --help                    Show help message
```

## ğŸ“Š Performance Metrics

### Real-time Performance Tracking
The pipeline provides comprehensive performance analytics:

```
ğŸ“Š DETAILED PERFORMANCE SUMMARY
================================================================================
ğŸ¬ sample_video_1.mp4 (sample_stream_1):
   ğŸ“Š Total Processing Time: 176.48s
   ğŸ” Total Inference Time: 145.04s (82.2% of processing)
   ğŸ“ˆ Average Inference per Frame: 483.46ms
   ğŸ¯ Processing FPS: 1.70
   ğŸ“‹ Total Frames: 300
   ğŸ” Total Detections: 53

ğŸ† OVERALL PERFORMANCE:
   â±ï¸  Total Pipeline Time: 177.32s
   ğŸ” Total Inference Time: 650.09s (366.6% of pipeline)
   ğŸ“ˆ Average Inference per Frame (All Videos): 481.90ms
   ğŸ“Š Total Frames Processed: 1349
   ğŸš€ Overall Processing FPS: 7.61
```

### Frame Preservation Verification
```
ğŸ‰ FINAL RESULTS:
  âœ… Perfect Compression: 5/5 videos (100%)
  âœ… Perfect Detection: 5/5 videos (100%)
  ğŸš€ Parallel Processing: ALL 5 videos processed independently
  ğŸ“Š Frame Preservation: 100% for both compression AND detection
  â±ï¸  Duration Preservation: 100% for both compression AND detection
```

## ğŸ”¬ Technical Details

### Processing Architecture
- **Threading-based Parallelism**: True concurrent processing using Python threading
- **Independent Processors**: Each video stream has its own detector instance
- **Memory Efficient**: Optimized memory usage with configurable buffer sizes
- **Frame-by-Frame Pipeline**: Sequential compression â†’ detection â†’ output per frame

### Compression Technology
- **JPEG Compression**: Configurable quality levels (1-100)
- **Lossless Processing**: No frame dropping or duration changes
- **Real-time Compression**: Applied per frame during processing
- **Quality Preservation**: Maintains visual quality while reducing file size

### Object Detection
- **YOLOv11 Small Model**: Latest YOLO architecture for optimal speed/accuracy
- **Real-time Inference**: Per-frame object detection
- **Visualization**: Bounding boxes with class labels and confidence scores
- **Multi-class Detection**: Supports all COCO dataset classes

### MLflow Integration
- **Experiment Tracking**: Automatic logging of all runs
- **Performance Metrics**: Detailed timing and accuracy metrics
- **Model Versioning**: Track model versions and parameters
- **Sample Logging**: Save sample detection frames for review

## ğŸ¯ Use Cases

### Industrial Applications
- **Security Surveillance**: Multi-camera object detection with compression
- **Quality Control**: Manufacturing defect detection with archival
- **Traffic Monitoring**: Vehicle detection across multiple intersections
- **Retail Analytics**: Customer behavior analysis with privacy-compliant compression

### Research Applications
- **Computer Vision Research**: Benchmarking detection algorithms
- **Performance Analysis**: Detailed timing and efficiency studies
- **Dataset Processing**: Batch processing of video datasets
- **Model Comparison**: A/B testing different detection models

## ğŸ”§ Customization

### Adding New Video Streams
```yaml
# Add to config.yaml
input_videos:
- path: videos/new_video.mp4
  stream_id: new_stream
```

### Custom Detection Models
```yaml
# Use different YOLO models
model:
  directory: model              # Keep all checkpoints here
  # name: custom_model.pt       # Optional explicit override
```

### Performance Tuning
```yaml
# High-performance setup
performance:
  max_workers: 5           # Full parallelism
  frame_buffer_size: 500   # Large buffer
  
model:
  device: cuda            # GPU acceleration
  
# Memory-constrained setup
performance:
  max_workers: 2          # Limited parallelism
  frame_buffer_size: 50   # Small buffer
  
model:
  device: cpu             # CPU processing
```

## ğŸ› Troubleshooting

### Common Issues

#### Performance Issues
- **Slow Processing**: Use GPU mode or reduce `max_workers`
- **Memory Issues**: Reduce `frame_buffer_size` or `max_workers`
- **High CPU Usage**: Switch to sequential mode for debugging

#### Output Issues
- **Missing Videos**: Check output directory permissions
- **Incomplete Videos**: Verify sufficient disk space
- **Quality Issues**: Adjust compression quality settings

#### Model Issues
- **Model Download Fails**: Check internet connection, manual download may be needed
- **CUDA Errors**: Verify CUDA installation and compatibility
- **Detection Accuracy**: Adjust confidence thresholds

### Debug Mode
```bash
# Enable debug logging
uv run main.py --log-level DEBUG

# Run single video for testing
# Edit config.yaml to include only one video
uv run main.py --parallel-mode sequential
```

## ğŸ“ˆ Performance Benchmarks

### Tested Configurations

| Configuration | Videos | Processing Time | Avg FPS | Memory Usage |
|---------------|--------|-----------------|---------|--------------|
| CPU (5 workers) | 5 | 177s | 7.6 | 8GB |
| CPU (2 workers) | 5 | 280s | 4.8 | 4GB |
| GPU (5 workers) | 5 | 95s | 14.2 | 12GB |
| Sequential | 5 | 450s | 3.0 | 2GB |

### System Requirements

| Component | Minimum | Recommended | High Performance |
|-----------|---------|-------------|------------------|
| CPU | 4 cores | 8 cores | 16+ cores |
| RAM | 8GB | 16GB | 32GB+ |
| GPU | None | GTX 1060 | RTX 3080+ |
| Storage | 10GB | 50GB | 100GB+ |

## ğŸ¤ Contributing

### Development Setup
```bash
# Install dependencies
uv sync

# Run tests
uv run pytest tests/

# Code formatting
uv run black main.py
uv run flake8 main.py
```

### Adding Features
1. **Fork the repository**
2. **Create feature branch**: `git checkout -b feature/new-feature`
3. **Make changes**: Modify `main.py` and update documentation
4. **Test thoroughly**: Ensure all existing functionality works
5. **Submit pull request**: Include detailed description of changes

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **Ultralytics**: YOLOv11 model implementation
- **OpenCV**: Computer vision and video processing
- **MLflow**: Experiment tracking and model management
- **PyTorch**: Deep learning framework

## ğŸ“ Support

For support and questions:
- **Issues**: Create GitHub issues for bugs and feature requests
- **Documentation**: Refer to INSTALLATION.md for detailed setup
- **Performance**: Check troubleshooting section for optimization tips

---

## ğŸš€ Quick Commands Reference

```bash
# Setup
uv sync

# Validate
uv run main.py --validate

# Run (CPU)
uv run main.py --parallel-mode threading --gpu cpu

# Run (GPU)
uv run main.py --parallel-mode threading --gpu cuda

# Debug
uv run main.py --log-level DEBUG --parallel-mode sequential

# Check Results
ls -la output/compressed/ output/detections/
```

**Ready to process your videos with enterprise-grade object detection and compression!** ğŸ¯